<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content=",,,," />





  <link rel="alternate" href="/atom.xml" title="小土刀" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="从这一课起，我们要开始使用数据库了。通过数据库和文件的性能对比以及 SQL 与 NoSQL 的对比，学会选择最合适的技术。">
<meta name="keywords">
<meta property="og:type" content="website">
<meta property="og:title" content="云计算 第 14 课 文件 vs 数据库">
<meta property="og:url" content="http://wdxtub.com/vault/cc-14.html">
<meta property="og:site_name" content="小土刀">
<meta property="og:description" content="从这一课起，我们要开始使用数据库了。通过数据库和文件的性能对比以及 SQL 与 NoSQL 的对比，学会选择最合适的技术。">
<meta property="og:image" content="http://wdxtub.com/images/14561603284363.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561643038821.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561643402177.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561733687303.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561824166535.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561876662637.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561876858760.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561903279207.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14561980518607.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562066176431.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562066977793.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562658234752.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562663033381.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562664950809.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14562672790636.jpg">
<meta property="og:updated_time" content="2016-03-11T21:15:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="云计算 第 14 课 文件 vs 数据库">
<meta name="twitter:description" content="从这一课起，我们要开始使用数据库了。通过数据库和文件的性能对比以及 SQL 与 NoSQL 的对比，学会选择最合适的技术。">
<meta name="twitter:image" content="http://wdxtub.com/images/14561603284363.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 4016951,
      author: '博主'
    }
  };
</script>

  <title>
  

  
    云计算 第 14 课 文件 vs 数据库 | 小土刀
  
</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=59042340";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <div style="display: none;">
    <script src="http://s6.cnzz.com/stat.php?id=1260625611&web_id=1260625611" type="text/javascript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-left  ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小土刀</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Agony is my triumph</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-work">
          <a href="/2016/09/11/work-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-pencil"></i> <br />
            
            作品
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech">
          <a href="/2009/09/11/tech-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-battery-full"></i> <br />
            
            技术
          </a>
        </li>
      
        
        <li class="menu-item menu-item-life">
          <a href="/1990/09/11/life-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-bolt"></i> <br />
            
            生活
          </a>
        </li>
      
        
        <li class="menu-item menu-item-booklist">
          <a href="/1997/09/11/booklist-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-diamond"></i> <br />
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-thanks">
          <a href="/thanks" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-gift"></i> <br />
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
      <p>从这一课起，我们要开始使用数据库了。通过数据库和文件的性能对比以及 SQL 与 NoSQL 的对比，学会选择最合适的技术。</p>
<a id="more"></a>
<hr>
<h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ol>
<li>了解使用文件来存储信息的优势和劣势</li>
<li>增加使用 <code>awk</code>, <code>grep</code> 等命令修改文件的经验</li>
<li>了解使用数据库来存储信息的优势和劣势</li>
<li>了解 MySQL (SQL) 和 HBase (NoSQL) 的不同</li>
<li>学会如何把数据载入到数据库中(MySQL, HBase)</li>
<li>学会使用 JDBC 连接 MySQL</li>
<li>学会使用 Java API 来操作 HBase</li>
<li>了解 vertical scaling 的在持久云存储（磁盘, 固态硬盘）的性能</li>
</ol>
<p>这次的作业主要用 Bash 和 Java(MySQL &amp; HBase) 在 AWS 平台上完成。</p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>近年来『数据』越来越被重视，这之中很重要的一环就是——如何存储这些数据。这一课中我们会接触常见的存储数据的方式，并学会在实际场景中根据需要选择合适的技术。</p>
<p>我们先会介绍<a href="https://en.wikipedia.org/wiki/Flat_file_database" target="_blank" rel="external">『文件』</a>以及『关系型数据库』</p>
<p>通常来说，我们用文件来保存非结构化的数据，用数据库来保存结构化的数据，我们来看看下面这个例子</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 文件中的一行</span></div><div class="line">Name: Carnegie, Course: Cloud Computing, Section: A, Year: 2015</div><div class="line"></div><div class="line"><span class="comment"># 数据库中的一行（有四列）</span></div><div class="line">Name           Course         Section     Year</div><div class="line">Carnegie    Cloud Computing      A        2015</div></pre></td></tr></table></figure>
<p>在数据库中，数据以表的形式存储，访问不同的元素比较简单，但是在文件中，就需要做一定的解析工作。文件和数据库各有所长，重要的还是具体问题具体分析，不能一概而论。</p>
<p>除了文件和传统的关系型数据库，NoSQL 数据库现在也越来越流行了。因为大数据面临的挑战，NoSQL 数据库在扩展性上比传统方法更好，但是却不得牺牲一些一致性和结构性来换取性能和可拓展性。</p>
<p>这节课我们同样会尝试在 HBase 上做一些操作。完成之后，应该能够对这三种方式有更加清晰的理解，以及能够根据实际使用场景来选择对应的方法。</p>
<h2 id="背景设定"><a href="#背景设定" class="headerlink" title="背景设定"></a>背景设定</h2><p>我们的目标是打造一个关于音乐和电影的社交网络，作为一个菜鸟，我拿到的第一个任务是分析音乐数据。在把服务部署到云上之前，公司希望我能评估一下用文件和用关系型数据库的性能比较。提供的数据文件如下：</p>
<p><img src="/images/14561603284363.jpg" alt=""></p>
<p>其中 <code>million_songs_metadata.csv</code> 包含所有歌曲的信息，<code>million_songs_sales_data.csv</code> 包含一段时间内每首歌的每日销量。具体的格式如下：</p>
<p><img src="/images/14561643038821.jpg" alt="Schema for file `million_songs_metadata.csv`"></p>
<p><img src="/images/14561643402177.jpg" alt="Schema for file `million_songs_sales_data.csv`"></p>
<p>最后注意要给所有用到的资源打上 <code>Project: 3.1</code> 的标签</p>
<h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><p>这一部分主要是使用 <code>grep</code> 和 <code>awk</code> 来进行一些简单的数据处理工作，关于这两个命令的使用，本来是打算专门写日志来说明的（然而一直没抽出时间），所以就尽量在这里介绍得清晰一点。</p>
<p>Grep 命令可以用来查找文件中出现的关键词或者某种固定的模式，如果我们要找到一个文件中包含 “The Beatles” 的记录，那么可以用以下命令：</p>
<p><code>grep -P &#39;The Beatles&#39; million_songs_metadata.csv</code></p>
<p>具体的查找过程可以有不同的参数进行设置，比方说下面的语句就会忽略大小写进行匹配：</p>
<p><code>grep -i -P &#39;The Beatles&#39; million_songs_metadata.csv</code></p>
<p>关于不同参数的意义，可以直接在命令行中输入 <code>man grep</code> 进行查看。</p>
<p>利用管道，我们可以统计具体的行数，比如：</p>
<p><code>grep -P &#39;The Beatles&#39; million_songs_metadata.csv | wc -l</code></p>
<p>用 grep 得到的结果，只要某一行出现了要找的内容，就算找到，但是如果我们想在指定的列中寻找特定的字符，就可以使用 awk 命令了。比方说，我们只想找出 <code>artist_name</code> 那一列中出现 “The Beatles” 的记录，就可以用下面的命令：</p>
<p><code>awk &#39; BEGIN {FS = &quot;,&quot;} ; {if ($7 ~ /The Beatles/) { print; }}&#39; million_songs_metadata.csv</code></p>
<p>这里 <code>$7</code> 表示是第 7 列，而 <code>FS = &quot;,&quot;</code> 表示分隔符是 <code>,</code></p>
<p>如果我们想要更复杂一点的逻辑，比如要找到 Michael Jacksn 80 年代的歌曲，就可以用这个命令：</p>
<p><code>awk &#39; BEGIN {FS = &quot;,&quot;} ; {if (tolower($7) ~ /michael jackson/ &amp;&amp; $11 &gt;= 1980 &amp;&amp; $11 &lt; 1990) { print; }}&#39; million_songs_metadata.csv</code></p>
<p>随着问题越来越复杂，可能很多时候都没有办法在一行内解决问题，不过在这一部分，我们还是尽量试试看用 grep 和 awk 解决问题。</p>
<p>做好准备之后可以开启一个 <code>ami-ca685ba0</code> 的 <code>t1.micro</code> 实例来完成下面的任务。</p>
<p>基本我们要做的就是把 <code>runner.sh</code> 补充完整，仔细读题，仔细读题，仔细读题（比如是否区别大小写）。</p>
<p>第五题可以写一个程序或者若干命令，以 <code>million_songs_metadata.csv</code> 和 <code>million_songs_sales_data.csv</code> 中相同 <code>track_id</code> 为标准，合并两个文件。生成一个 <code>million_songs_metadata_and_sales.csv</code> 数据集，其中第 1 列是 <code>track_id</code>，第 2 列是 <code>sales_date</code>，第 3 列是 <code>sales_count</code>，第 4 - 13 列是 <code>million_songs_metadata.csv</code> 的其他列。</p>
<p>完成问题之后，可以使用 <code>./runner.sh files</code> 来检查输出结果</p>
<p><strong>提示</strong></p>
<ol>
<li>搜索找到一个能够完成合并文件的 unix 命令</li>
<li>只能用命令行脚本完成</li>
<li>不要使用 Java 和 Python</li>
<li>没有特别声明，所有的匹配都是大小写敏感的</li>
<li>第六题中，一个歌手可能有多个 <code>artist_names</code>，但是只会有一个唯一的 <code>artist_id</code>，应该根据 <code>artist_id</code> 来找到最大的销量，并返回所有 <code>artist_name</code></li>
<li>注意保存好 <code>runner.sh</code></li>
</ol>
<h3 id="解题攻略"><a href="#解题攻略" class="headerlink" title="解题攻略"></a>解题攻略</h3><p>首先先创建一个 <code>ami-ca685ba0</code> 的 <code>t1.micro</code> 实例。就绪之后 ssh 过去：<code>ssh -i demo.pem ubuntu@ec2-54-175-177-74.compute-1.amazonaws.com</code>，即可见到这次作业的相关文件：</p>
<p><img src="/images/14561733687303.jpg" alt=""></p>
<p>这部分我们只需要用 <code>runner.sh</code>，所以把它搞到本地 <code>scp -i demo.pem ubuntu@dns.compute-1.amazonaws.com:~/Project3_1/runner.sh ./</code></p>
<p>打开 <code>runner.sh</code> 文件，可以看到需要回答的问题是：</p>
<ol>
<li>在文件 <code>million_songs_metadata.csv</code> 中，有多少行包含 <code>Aerosmith</code>，大小写敏感</li>
<li>在文件 <code>million_songs_metadata.csv</code> 中，<code>artist_name</code> 包含 <code>Bob Marley</code> 的 <code>track_id</code> 有多少个，大小写敏感</li>
<li>在文件 <code>million_songs_metadata.csv</code> 中，第 7 列中包含 <code>The Beatles</code> 的有多少行，大小写敏感</li>
<li>写出与 SQL 命令 <code>SELECT AVG(duration) FROM songs</code> 等价的命令行命令</li>
<li>把两个 csv 文件合并为 <code>million_songs_metadata_and_sales.csv</code>，以相同 <code>track_id</code> 为标准</li>
<li>在文件 <code>million_songs_metadata_and_sales.csv</code> 中，找到销量最高的 artist，一个歌手可能有多个 <code>artist_names</code>，但是只会有一个唯一的 <code>artist_id</code>，应该根据 <code>artist_id</code> 来找到最大的销量，并返回所有 <code>artist_name</code></li>
</ol>
<p>写好之后传到服务器上：<code>scp -i demo.pem ./runner.sh ubuntu@dns.compute-1.amazonaws.com:~/Project3_1/</code></p>
<p>测试的话用 <code>./runner.sh files</code>，确定无误后使用 <code>./submitter -a dawang</code> 来进行提交，代码运行完成后输入提交密码即可。</p>
<h2 id="MySQL-操作"><a href="#MySQL-操作" class="headerlink" title="MySQL 操作"></a>MySQL 操作</h2><p>同样是使用 <code>ami-ca685ba0</code> 的 <code>t1.micro</code> 实例来完成这部分的内容</p>
<p>先通过<a href="https://youtu.be/x73HknyUGIM" target="_blank" rel="external">视频</a>来了解 MySQL 的基础知识</p>
<p>远程机器中已经安装配置好了 MySQL，使用下面的命令可以开启 MySQL 命令行客户端并且连接到数据库：</p>
<p><code>mysql -u root -pdb15319root song_db</code></p>
<p>上面的命令中，用户名是 <code>root</code> 密码是 <code>db15319root</code>，使用是数据名称是 <code>song_db</code></p>
<p>数据库的相关知识可以参考<a href="https://zh.wikipedia.org/wiki/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93" target="_blank" rel="external">这里</a>，就不在日志中赘述。</p>
<p>我们需要根据前面给出 schemas 来创建对应的表，作业文件中提供了 <code>~/Project3_1/create_tables.sql</code> 文件，可以从这里开始</p>
<blockquote>
<p>远程主机中的 MySQL 版本是 5.5，注意查看对应的文档</p>
</blockquote>
<p>创建好之后，可以使用下面的命令来查看表的 schema</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">DESCRIBE</span> songs;</div><div class="line"><span class="keyword">DESCRIBE</span> sales;</div></pre></td></tr></table></figure>
<p>然后和前面给出的表格进行比较，看看是否一致。</p>
<p>所以我要做的是找到合适的命令，把 <code>million_songs_metadata.csv</code> 和 <code>million_songs_sales.csv</code> 导入到 MySQL 中。可以在 MySQL 命令行工具中使用 SQL 命令导入，也可以用 mysqlimport 工具来导入，记下所使用的命令即可。</p>
<p>想要验证是否导入成功的话，可以列出前十条记录：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> songs </div><div class="line"><span class="keyword">LIMIT</span> <span class="number">10</span>;</div></pre></td></tr></table></figure>
<p>SQL 的语法可以参考<a href="http://www.w3school.com.cn/sql/sql_syntax.asp" target="_blank" rel="external">这里</a>，下面选出一些简单的例子进行介绍。</p>
<p>比如说下面的命令就会从表中选出 <code>artist_name</code> 一列中包含 <code>The Beatles</code> 的表项：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> songs </div><div class="line"><span class="keyword">WHERE</span> artist_name </div><div class="line"></div><div class="line"><span class="keyword">LIKE</span> <span class="string">'%The Beatles%'</span>;</div></pre></td></tr></table></figure>
<p>这里的 <code>%</code> 表示任何字符出现任意次数，前面提到的寻找 <code>Michael Jackson</code> 的例子可以写成：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> songs </div><div class="line"><span class="keyword">WHERE</span> artist_name </div><div class="line"><span class="keyword">LIKE</span> <span class="string">'%michael jackson%'</span><span class="keyword">AND</span> <span class="keyword">year</span> &gt;= <span class="number">1980</span> <span class="keyword">AND</span> <span class="keyword">year</span> &lt; <span class="number">1990</span>;</div></pre></td></tr></table></figure>
<p>如果需要计算平均时间，就不需要使用 <code>awk</code> 命令那么复杂，可以直接</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> <span class="keyword">AVG</span>(<span class="keyword">duration</span>) <span class="keyword">FROM</span> songs;</div></pre></td></tr></table></figure>
<p>带索引的数据库可以极大提高查询的性能，在 MySQL 中，所有的主键都会自动成为索引。</p>
<p>Aggregate Functions 允许你在多个记录中执行运算并返回一个单一值，比较常用的有 <code>SUM</code>, <code>AVG</code>, <code>MAX</code>, <code>MIN</code> 和 <code>COUNT</code>. Aggregate functions 通常和 MySQL 的 GROUP BY 关键字一起使用来为不同的 subgroup 执行运算并返回对应结果。GROUP BY 非常有用，下面是一个例子：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> c1, c2, ... cn, aggregate_function(expression)</div><div class="line"><span class="keyword">FROM</span> <span class="keyword">table</span></div><div class="line"><span class="keyword">WHERE</span> where_conditions</div><div class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> c1, c2, ... cn;</div></pre></td></tr></table></figure>
<p>例如，要统计最近十天总销量排名，可以用下面的 SQL 语句：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> sales_date, <span class="keyword">SUM</span>(sales_count) <span class="keyword">AS</span> total_sales</div><div class="line"><span class="keyword">FROM</span> sales</div><div class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> sales_date</div><div class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> sales_date <span class="keyword">DESC</span></div><div class="line"><span class="keyword">LIMIT</span> <span class="number">10</span>;</div></pre></td></tr></table></figure>
<p>MySQL 的 JOIN 关键字可以用来在两个或两个以上相关的表中进行查询。在 MySQL 中 <code>JOIN</code>, <code>CROSS JOIN</code> 和 <code>INNER JOIN</code> 是等价的，下面是一个例子：syntax:</p>
<figure class="highlight"><table><tr><td class="code"><pre><div class="line">#select statement</div><div class="line">    SELECT c1,c2,....cn</div><div class="line">    FROM join_table;</div><div class="line">#join_table</div><div class="line">    table1 [INNER|CROSS] JOIN table2 [join_condition]</div><div class="line">#join_condition:</div><div class="line">    ON conditional_expr</div><div class="line">  | USING (column_list)</div></pre></td></tr></table></figure>
<p><code>INNER JOIN</code> 会构造指定的表的笛卡尔乘积，也就是第一个表中的每一行通过 join condition 和第二个表中的每一行组合。因为我们的 songs 表中的所有 <code>track_ids</code> 在 sales 表中都有对应的记录，所以这里只用 <code>INNER JOIN</code> 即可。</p>
<p>例如，下面的 SQL 语句会返回销量最高的 10 首歌的名字：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> songs.title, <span class="keyword">SUM</span>(sales_count) <span class="keyword">AS</span> total_sale</div><div class="line"><span class="keyword">FROM</span> songs</div><div class="line"><span class="keyword">INNER</span> <span class="keyword">JOIN</span> sales <span class="keyword">ON</span> songs.track_id = sales.track_id</div><div class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> sales.track_id</div><div class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> total_sale</div><div class="line"><span class="keyword">DESC</span> <span class="keyword">LIMIT</span> <span class="number">10</span>;</div></pre></td></tr></table></figure>
<blockquote>
<p>关于 OUTER JOIN</p>
</blockquote>
<p>和 INNER JOIN 不同的是可能会出现列的值为空的情况，根据提供不匹配的数据的表所在的位置，分为 LEFT 和 RIGHT JOINS。在 LEFT JOIN 中，会返回左边表中不匹配的记录，反之亦然。没有匹配的话，会把对应的列设为 NULL。如果想要保留不匹配的数据，这种方法就很有用了。</p>
<h3 id="JDBC-和-MySQL"><a href="#JDBC-和-MySQL" class="headerlink" title="JDBC 和 MySQL"></a>JDBC 和 MySQL</h3><p>Java Database Connectivity (JDBC) API 可以用来访问数据库，并且由于是一个跨平台的标准，在不同的平台上可以使用相同的代码。这一部分我们会使用 MySQL Connector/J。</p>
<p>第一步就是与数据建立连接，如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">Class.forName(<span class="string">"com.mysql.jdbc.Driver"</span>);</div><div class="line">Connection conn = DriverManager.getConnection(URL, DB_USER, DB_PWD);</div></pre></td></tr></table></figure>
<p>第一行载入并初始化 MySQL 的 JDBC 驱动，然后我们就可以建立与数据库的连接（参数比较简单这里略过）</p>
<p>为了执行 SQL 操作以及获取执行完毕的结果，我们需要创建 Statement(用来执行 SQL 命令的对象)，并且在执行完成后得到一个 ResultSet 对象，下面是一个例子：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">Statement stmt = conn.createStatement();</div><div class="line">ResultSet rs = stmt.executeQuery(<span class="string">"select count(*) as cnt from songs;"</span>);</div></pre></td></tr></table></figure>
<p>可以通过调用 <code>rs.next()</code> 来遍历结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">while (rs.next()) &#123;</div><div class="line">    int rowCount = rs.getInt(&quot;cnt&quot;);</div><div class="line">    System.out.println(&quot;Total number of lines in songs is &quot; + rowCount);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>执行完对应操作后，还需要关闭我们用到的 Statement 和 Connection，注意关闭 Statement 之后对应的 ResultSet 也会被关闭。</p>
<h3 id="解题攻略-1"><a href="#解题攻略-1" class="headerlink" title="解题攻略"></a>解题攻略</h3><p>和之前一样，我们要做的就是完成 7-11 题，需要修改 <code>MySQLTasks.java</code> 文件。仔细读题，仔细读题，仔细读题。</p>
<p>第 7-9 题我们需要为 songs 表创建索引。那么应该选择哪一列作为索引呢？</p>
<p>记录下使用的命令已经对应更新 <code>INDEX_NAME</code> 变量，建立索引需要花一点时间，不过可以换取比较大的性能提升，建立完索引后，使用下面的命令重启 mysql：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">sudo service mysql restart</div></pre></td></tr></table></figure>
<p>在第 9 题中，我们会使用和第 7 题一样的指令，就可以看到建立索引之后的性能提升。</p>
<p>开始写代码之前，可以先运行一下样例，了解 java 如何和 MySQL 交互。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">javac MySQLTasks.java</div><div class="line">java MySQLTasks demo</div></pre></td></tr></table></figure>
<p>会输出 songs 表中的行数（如果存在的话），做完之后可以用 <code>./runner.sh mysql</code> 来检查。</p>
<p><strong>Bonus</strong></p>
<p>如果完成 <code>MySQLTasks.java</code> 中的 <code>loadData</code> 函数，有 5 分的加分，可以通过下面代码进行测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">javac MySQLTasks.java</div><div class="line">java MySQLTasks load_data</div></pre></td></tr></table></figure>
<p><strong>一些提示</strong></p>
<ul>
<li>SQL 的 LIKE 操作符默认是大小写不敏感的</li>
<li>记得把所有的答案输出到同一行</li>
<li>下一部分也可以用同一个远程机器，终止之前保存好所有的代码</li>
</ul>
<p>文件更灵活，可以存放结构或非结构数据，并且容易实现和修改；数据库则稍微笨重一些。对于文件来说，安全只能通过文件权限来控制，但是数据库有更加完善的权限管理。对文件的访问没有办法并行，但是数据库访问则可以。其他的不同基本上可以认为数据库有一套完整的管理接口和语法，而文件的话都需要自己实现，下表是一个总结：</p>
<p><img src="/images/14561824166535.jpg" alt="文件 vs 数据库"></p>
<p>首先我们把对应的文件复制到本地：<code>scp -i demo.pem ubuntu@dns.compute-1.amazonaws.com:~/Project3_1/MySQLTasks.java ./</code></p>
<p>然后我们可以用给出的 <code>create_tables.sql</code> 来新建数据表，先进入 MySQL 的命令行：<code>mysql -u root -pdb15319root song_db</code></p>
<p>然后输入 <code>source ./create_tables.sql</code> 来执行新建表格的命令。接着可以用 <code>DESCRIBE songs;</code> 和 <code>DESCRIBE sales;</code> 来查看是否成功创建（注意一定要最后的分号），如图</p>
<p><img src="/images/14561876662637.jpg" alt="songs 表"><br><img src="/images/14561876858760.jpg" alt="sales 表"></p>
<p>然后需要找到合适的命令，把 <code>million_songs_metadata.csv</code> 和 <code>million_songs_sales.csv</code> 导入到 MySQL 中（这里推荐用 <code>mysqlimport</code> 来导入，另一个有点问题）。命令为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line"><span class="comment"># 需要先更改两个 scv 文件的名字，这样才能载入到对应的表中</span></div><div class="line">cp million_songs_metadata.csv songs.csv</div><div class="line">cp million_songs_sales_data.csv sales.csv</div><div class="line"><span class="comment"># 然后进行载入</span></div><div class="line">mysqlimport -u root -pdb15319root --local --fields-terminated-by=<span class="string">","</span> --lines-terminated-by=<span class="string">"\n"</span> song_db songs.csv</div><div class="line">mysqlimport -u root -pdb15319root --local --fields-terminated-by=<span class="string">","</span> --lines-terminated-by=<span class="string">"\n"</span> song_db sales.csv</div></pre></td></tr></table></figure>
<p>然后我们用下面的命令来看看是否成功（如果不成功，就重新用前面的脚本生成一次对应的表）：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> songs <span class="keyword">LIMIT</span> <span class="number">10</span>;</div><div class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> sales <span class="keyword">LIMIT</span> <span class="number">10</span>;</div></pre></td></tr></table></figure>
<p>大概应该看到</p>
<p><img src="/images/14561903279207.jpg" alt=""></p>
<p>然后就可以进入写 java 代码的阶段了，先大概看一下已有的代码，发现已经帮我们初始化过了，实际上只要在代码中填写对应的 SQL 语句即可。问题为（第 7-11 题）：</p>
<ol>
<li>(7)返回 duration 最长的歌的 trackid</li>
<li>(8)选择一列作为索引，并建立索引</li>
<li>(9)返回 duration 最长的歌的 trackid（和第 1 个题目相同，用来比较性能）</li>
<li>(10)写一条与 <code>grep -P &#39;The Beatles&#39; million_songs_metadata.csv | wc -l</code> 等价的 sql 语句，这里注意大小写的问题，提示：<code>BINARY</code>（感谢 @jiexing）</li>
<li>(11)哪个 artist 的歌曲数目是第三多的，返回其名字，如果有多个，任意一个都可以</li>
</ol>
<p>其实主要就是写出对应的 SQL 语句，执行起来都是一样的，前面也有给出例子。然后就可以上传回服务器：<code>scp -i demo.pem ./MySQLTasks.java ubuntu@dns.compute-1.amazonaws.com:~/Project3_1/</code></p>
<p>测试的话用 <code>./runner.sh mysql</code>，确定无误后使用 <code>./submitter -a dawang</code> 来进行提交，代码运行完成后输入提交密码即可。</p>
<h2 id="Vertical-Scaling-存储"><a href="#Vertical-Scaling-存储" class="headerlink" title="Vertical Scaling 存储"></a>Vertical Scaling 存储</h2><p>那么问题来了，我们的数据到底保存在哪里呢？当然是物理世界的硬盘上，但是我们之前好像都没有考虑到这个事情，事实上，不同的硬盘对性能也有极大的影响。</p>
<p>接下来的部分我们会了解一些 Linux 下的磁盘操作命令并且利用 AWS 提供的存储设备来进行 vertical scaling。并且用常见的 benchmarking 工具来进行测试，通过整个过程，应该就能了解为什么实际存储数据的设备也对性能有极大的影响。</p>
<p>因为大多数命令都需要 root 权限，所以开始之前 <code>sudo su</code> 一下是比较方便的选择。</p>
<p>这个<a href="https://youtu.be/8Bwg_wUVhkE" target="_blank" rel="external">视频</a>介绍如何在 EC2 实例中使用 EBS</p>
<ul>
<li>一般来说在创建 EC2 实例的时候会自动创建一个 EBS 并挂载到 EC2 实例上</li>
<li>先进入 EBS Volume 页面，Create Volume -&gt; 选择不同的大小 -&gt; 选择 Availablility Zone(要和 EC2 在同一个区域) -&gt; Create</li>
<li>点击 Action -&gt; Attach Volumn -&gt; 选择已有的实例 -&gt; 填写挂载点 <code>/dev/sdf</code></li>
<li>ssh 到机器上，输入命令 <code>sudo parted -l</code> 可以发现并没有成功挂载</li>
<li>我们在磁盘上新建一个文件系统：<code>sudo mkfs.ext4 /dev/xvdf</code></li>
<li>再次运行 <code>sudo parted -l</code>，发现一切正常</li>
<li>然后创建文件夹用来挂载 <code>sudo mkdir /mnt/ebs1</code></li>
<li>接着进行挂载 <code>sudo mount /dev/xvdf /mnt/ebs1</code></li>
<li>就可以访问对应文件夹了 <code>cd /mnt/ebs1/</code></li>
<li>最后可以用 <code>df -h</code> 来进行查看</li>
</ul>
<p>GNU <code>parted</code> 是用来创建、销毁、改变大小、检查状态、复制分区的命令，可以操作分区表（取代原来的 <code>fdisk</code>），并支持如 GUID Partition Table(GPT) 等的新特性。想要了解更多可以参考<a href="https://www.gnu.org/software/parted/manual/html_chapter/parted_1.html" target="_blank" rel="external">这里</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">parted <span class="_">-l</span></div><div class="line">/dev/xvda1 – this is the OS partition</div><div class="line">/dev/xvdb – this is the first Ephemeral (instance store) drive</div><div class="line">/dev/xvdc – this is the second Ephemeral (instance store) drive</div></pre></td></tr></table></figure>
<p>创建并格式化一个分区</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">umount /dev/xvdX <span class="comment">#where “X” - is a,b,c..etc (You should use your device’s name)</span></div><div class="line">parted /dev/xvdX mklabel gpt</div><div class="line">parted /dev/xvdX mkpart db ext4 0% 10G</div><div class="line">mkfs.ext4 /dev/xvdX1</div></pre></td></tr></table></figure>
<p>对于比较小的 volume，可以直接整个格式化，不用分区</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">mkfs.ext4 /dev/xvdX</div></pre></td></tr></table></figure>
<p>创建挂载点并挂载</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">mkdir /storage/mountpoint</div><div class="line">mount /dev/yourdevice /storage/mountpoint</div></pre></td></tr></table></figure>
<p>到底用不用挂载点可以自己决定，不过一般来说 Linux 会挂载到 <code>/mnt</code>（EC2 也是这么做的）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">mount</div></pre></td></tr></table></figure>
<p>不带任何参数的话会显示所有的挂载点，可以用来判断是否挂载成功。</p>
<h3 id="解题攻略-2"><a href="#解题攻略-2" class="headerlink" title="解题攻略"></a>解题攻略</h3><p>简单来说就是比较传统硬盘和固态硬盘的性能差别，测试的场景如下：</p>
<p><img src="/images/14561980518607.jpg" alt=""></p>
<p>Sysbench 是一个包含多个测试的评测。这里我们使用的评测程序和 sysbench 唯一不同的是可以选择 [SSD|Magnetic]。</p>
<p>根据下面的指示完成不同配置的测试，记录下不同的 RPS，把数字填写到对应的位置即可。</p>
<blockquote>
<p>提示：使用比较慢的硬件时，准备 10GB 的数据可能要花费很长时间，用最好的的机器（比如 large）来准备数据</p>
</blockquote>
<p><strong>准备测试数据</strong></p>
<p>步骤如下</p>
<ol>
<li>用 <code>ami-ca685ba0</code> 启动一个 <code>t1.micro</code> 或 <code>m3.large</code> 的实例</li>
<li>创建一个 20GB 的 EBS volume (磁盘或固态硬盘) 。确保和 EC2 实例在同一个区域</li>
<li>把 EBS volume 挂载到 EC2 实例上</li>
<li>SSH 到 EC2 实例，格式化并挂载 EBS volume</li>
<li>进入挂载文件夹</li>
<li>用下面的命令生成测试数据 <code>sudo /home/ubuntu/Project3_1/sysbench --test=fileio --file-total-size=10G prepare</code></li>
</ol>
<p>上面的命令会在 EBS volume 上生成 10GB 的测试数据，在接下来的步骤中都可以重复使用</p>
<p><strong>试验 1 (上表中 Scenarios 1 &amp; 2 )</strong></p>
<p>执行以下步骤：</p>
<ol>
<li>启动一个 <code>ami-ca685ba0</code> 的 <code>t1.micro</code> 实例</li>
<li>挂载上 EBS volume </li>
<li>确保挂载成功</li>
<li>执行下面的代码 3 次（中间不要间隔太长时间）<code>sudo /home/ubuntu/Project3_1/sysbench --test=fileio --file-total-size=10G --file-test-mode=rndrw --max-time=300 --max-requests=0 run</code></li>
<li>把结果写到 <code>runner.sh</code> 中</li>
<li>使用另外的磁盘类型进行测试</li>
</ol>
<blockquote>
<p>暂时不要删除 EBS volume，之后还有用</p>
</blockquote>
<p><strong>试验 2 (上表中 Scenarios 3 &amp; 4 )</strong></p>
<ol>
<li>启动一个 <code>ami-ca685ba0</code> 的 <code>m3.large</code> 实例</li>
<li>挂载上 EBS volume </li>
<li>确保挂载成功</li>
<li>执行下面的代码 3 次（中间不要间隔太长时间）<code>sudo /home/ubuntu/Project3_1/sysbench --test=fileio --file-total-size=10G --file-test-mode=rndrw --max-time=300 --max-requests=0 run</code></li>
<li>把结果写到 <code>runner.sh</code> 中</li>
<li>使用另外的磁盘类型进行测试</li>
</ol>
<p>测试的话用 <code>./runner.sh scaling</code>，确定无误后使用 <code>./submitter -a dawang</code> 来进行提交，代码运行完成后输入提交密码即可。</p>
<h2 id="HBase-操作"><a href="#HBase-操作" class="headerlink" title="HBase 操作"></a>HBase 操作</h2><p>Apache HBase 是一个开源版本的 Google BigTable 分布式存储系统，其特点是分布式，可拓展，高性能，为大数据而生，在 Hadoop Distributed File System (HDFS) 上工作。HBase 在不同的服务器上把文件保存为重复的块，HDFS 保证其扩展性和可靠性。</p>
<p>在 HBase 中，输入按照行列排列，如下图所示：</p>
<p><img src="/images/14562066176431.jpg" alt="HBase table 的典型架构"></p>
<p>HBase 中的每一行都有对应的 row key，类似于主键，必须是唯一的。HBase 会自动根据 row key 来排列数据，默认按照字节顺序排序。</p>
<p>如上图所示，每一行包括：<code>rowkey</code>, <code>column_family</code>, <code>column</code> 和 <code>timestamp</code>，所以整个的映射变成 <code>(rowkey, column family, column, timestamp) -&gt; value</code>。Rowkey 和 value 都是简单的字节，所以只要能序列化成字节的都可以保存在 cell 中。这些 cell 会按照字典序排列，这是一个非常重要的特性，使得 HBase 支持快速搜索。</p>
<p>HBase 中的每一列都有列名，还可以进一步组织成 column family。所有的 column family 成员拥有共同的前缀，如上图所示，列 Metadata:Type 和列 Metadata:Language 都是 Metadata column family 的成员，而列 Content:Data 则属于 Content family。默认来说用冒号来分隔 column family 的前缀，这个前缀必须由能够打印的字符组成，后面的部分可以是任何字节。</p>
<p><strong>HBase 操作</strong></p>
<p>HBase 有四个主要的操作：Get, Put, Scan, 和 Delete.</p>
<ul>
<li>Get 操作会返回指定行的所有 cell</li>
<li>Put 操作可以添加新的记录或者更新已有记录</li>
<li>Scan 操作会根据条件遍历多行记录</li>
<li>Delete 操作会移除一条记录</li>
</ul>
<p>Get 和 Scan 操作的返回都是排好序的，依据为 rowkey, column family, family 成员，和时间戳（也就是最新的值会在最前面）。默认来说，Get, Scan 和  Delete 操作都是在数据最新的版本上的（也可以指定其他版本的数据）。Delete 操作一般来说会删除整行，但是也可以删除指定的 cell。</p>
<p><strong>HBase 架构</strong></p>
<p>HBase 是以 HBase 节点集群来进行组织的，节点有两种类型：master 和 slave（也叫 RegionServers）</p>
<p><img src="/images/14562066977793.jpg" alt="HBase 集群架构"></p>
<p>HBase 会动态分配数据表，这样支持大量的并行访问。一个 HBase 表在太大时会被分成多个 Region，一个 HBase Region 是一个 HBase 表的子集，但是 rowkey 的范围是连续的。每个  RegionServer 可以保存多个 Regions，但是一个 Region 只会在一个 RegionServer 上。</p>
<p>虽然一个 Region 只会在一个 RegionServer 上，但是这不意味着该 Region 部分的数据只能存在于一个 RegionServer 上。事实上，因为 HDFS 的复制机制，每个 Region 都会在其他 RegionServer 上有几份一模一样的拷贝。想要了解更多？查看 <a href="http://hbase.apache.org/book.html" target="_blank" rel="external">HBase Reference Guide</a> 以及 <a href="https://blogs.apache.org/hbase/" target="_blank" rel="external">HBase 博客</a>.</p>
<p>HBase 使用 Apache ZooKeeper 来协调控制整个 HBase 集群。Apache ZooKeeper 需要做的事情有：选择 master 节点，寻找 -ROOT- catalog table 以及节点注册（当新的 RegionServer 加入的时候）。由 ZooKeeper 选择出来的 master 节点会处理诸如 region 分配，失败处理，负载均衡等任务。</p>
<p>HBase 使用 HDFS 作为存储，但是同样支持其他文件系统（本地文件系统，甚至 Amazon S3）。</p>
<p>这个 <a href="https://youtu.be/lUOFLa0DKdc" target="_blank" rel="external">HBase Demo</a> 视频会介绍 HBase 的基本使用，虽然视频中的 EMR 版本较旧，但是对我们这次的任务没有什么影响。</p>
<ul>
<li>Costs = Instance + EMR costs</li>
<li>进入 EMR 页面 -&gt; 创建集群 -&gt; 输入名字 -&gt; 开启关闭保护 </li>
<li>选择 S3 的 log bucket -&gt; 打上标签 -&gt; 去掉 pig 和 hive，改为 HBase </li>
<li>选择 spot -&gt; 指定 keypair -&gt; 需要等待一段时间开启</li>
<li>ssh 到 master public dns，注意这里用户名是 hadoop 而不是 ubuntu</li>
<li><code>hbase shell</code> -&gt; <code>&gt; help</code> 查看帮助 -&gt; <code>&gt; status</code> 查看状态</li>
<li><code>create &#39;users&#39;, &#39;info&#39;</code> 创建表格</li>
<li><code>describe &#39;users&#39;</code> 可以查看表格内容</li>
<li><code>put &#39;user&#39;, &#39;johndeo&#39;, &#39;info&#39;, &#39;regularUser&#39;</code> 插入一条记录</li>
<li><code>get &#39;users&#39;, &#39;johndoe&#39;</code> 获取一条记录</li>
<li><code>scan &#39;users&#39;</code> 遍历某个表并输出</li>
<li><code>count &#39;users&#39;</code> 统计表的行数</li>
</ul>
<blockquote>
<p>注意：EMR 很贵，最好使用 spot instance</p>
</blockquote>
<h3 id="使用-EMR-创建-HBase-集群"><a href="#使用-EMR-创建-HBase-集群" class="headerlink" title="使用 EMR 创建 HBase 集群"></a>使用 EMR 创建 HBase 集群</h3><p>我们将使用 EMR 创建 HBase 集群。HBase 使用 Hadoop Distributed File System (HDFS) 来存储数据。默认来说 AWS 会直接用 EC2 内置的存储给 HDFS 使用，下面是具体的使用步骤：</p>
<ol>
<li>启动 EMR 集群：1 master &amp; 1 core <ul>
<li>在创建页面中选择 “Go to advanced options”</li>
<li>确保所有的实例都是 m1.large</li>
<li>确保 EMR 集群和存放 <code>runner.sh</code> 的实例在同一个区域</li>
<li>选择 AMI version 3.11.0 (hadoop version 2).</li>
<li>移除所有的已有服务(Pig &amp; Hive)并选择安装 HBase version 0.94.</li>
<li>指定 key-pair 以便 SSH 到 master 实例，ssh 的时候注意用户名是 hadoop</li>
<li>不要忘记设置标签</li>
<li>开启 “termination protection” 和 “keep-alive”</li>
</ul>
</li>
<li>master 和 core 节点的安全组都允许所有流量，使用 Master public DNS 来进行连接</li>
<li>ssh 到 master 节点之后，运行 <code>hadoop dfsadmin -report</code> 检查 HDFS 的状态</li>
</ol>
<h3 id="载入数据到-HBase"><a href="#载入数据到-HBase" class="headerlink" title="载入数据到 HBase"></a>载入数据到 HBase</h3><p>HBase 支持多种数据导入方法，这里我们介绍 Bulk Load 方法。</p>
<p>最直接的载入办法可以是在 MapReduce job 中使用 <code>TableOutputFormat</code> 类，也可以使用client APIs，但是这可能不是最有效率，因为 API 不支持 bulk loading.</p>
<p>Bulk Importing 会越过 HBase API 直接写入到数据文件中(HFiles)。使用 bulk load 可以减少 CPU 和网络带宽的占用。<code>ImportTsv</code> 就可以完成这个任务，虽然原本是为 TSV (Tab Separated Value) 格式设计的，但是通过设置参数，同样支持 CSV 文件，步骤如下：</p>
<ol>
<li>把 TSV/CSV 格式的数据集上传到 HDFS (Hadoop Distributed File System)<ul>
<li>File System (FS) shell 支持基本的文件操作比如 <code>Local FS</code>, <code>HFTP FS</code>, <code>S3 FS</code> 等等，可以通过 <code>hadoop fs &lt;args&gt;</code> 来调用</li>
<li>从 S3 bucket 获取 <code>million_songs_metadata.csv</code> 文件<ul>
<li><code>mkdir P3_1</code></li>
<li><code>cd P3_1</code></li>
<li><code>wget https://s3.amazonaws.com/15319-p31/million_songs_metadata.csv</code></li>
</ul>
</li>
<li>把下载下来的文件保存到 HDFS 中以便导入，具体命令需要自己寻找</li>
<li>可以用 <code>hadoop fs -ls /path/containing/your/uploaded/file</code> 来检测是否上传成功</li>
</ul>
</li>
<li>打开 HBase shell (<code>HBase shell</code>)并新建一个名为 songdata 的表(使用 <code>create</code> 命令，后面跟 column family name 的名字)。建立成功之后使用 <code>exit</code> 命令退出</li>
<li>为 HBase 表准备好 HFiles。使用 <code>ImportTsv</code> 命令把文件 <code>million_songs_metadata.csv</code> 中的数据传到 HDFS 中，名为 <code>importtsv.bulk.outputHbase</code>。这些 StoreFiles 之后会被载入到 HBase 中。注意这里我们使用 <code>track_id</code> 作为 row key，其他的列会成为 column family name (这里使用 ‘data’)。要了解 <code>ImportTsv</code> 的更多信息，请参考 <a href="http://hbase.apache.org/0.94/book/ops_mgt.html#importtsv" target="_blank" rel="external">official reference</a>.</li>
<li>正常启动的话，我们可以看到 MapReduce 工作的进程</li>
<li>检查 Map 步骤的输出来验证结果。通常来说应该会与数据集中的数据数量相等。注意，对应的输出文件应该是不存在的（不然会导致任务失败）</li>
<li>前面所做的所有工作都只是为了把数据保存到 HBase 中，但是此时 HBase 的表仍旧是空的（还没有添加对应的记录）</li>
<li>需要使用 CompleteBulkLoad 工具来完成数据上传，参考官方文档来使用</li>
<li>现在可以验证数据是否成功上传，打开 HBase shell 然后用以下命令来查看 <code>scan &#39;songdata&#39;</code></li>
<li>用 Ctrl-C 结束输出</li>
</ol>
<p>当然，除了这个方法，也可以在 MapReduce job 中使用 <code>TableOutputFormat</code> 或者其他 HBase client API。</p>
<h3 id="HBase-查询"><a href="#HBase-查询" class="headerlink" title="HBase 查询"></a>HBase 查询</h3><p>与 MySQL 类似，HBase 提供了查询的工具。在 HBase 中，数据存在 column 中，多个 column 组成 column family。我们可以用下面的指令来进行查询：</p>
<p><code>scan ‘table_name’, {COLUMNS =&gt; [‘column1’, ‘column2’, …], FILTER =&gt; “(FILTER1) … (FILTER2)”}</code></p>
<p>我们来做一个和之前类似的查询，找到所有 <code>artist_name</code> 以 “The Beatles” 开头的记录（是一个前缀匹配，不是子串匹配），查询如下：</p>
<p><code>scan &#39;songdata&#39;, {COLUMNS =&gt; &#39;data:artist_name&#39;, FILTER =&gt; &quot;SingleColumnValueFilter(&#39;data&#39;, &#39;artist_name&#39;, = , &#39;regexstring:^The Beatles.*&#39;)&quot;}</code></p>
<p>这里的列名的格式是 <code>(column family name):(column qualifier name)</code>。并且返回的数据中只包含了 <code>artist_name</code> 的数据，如果我们想多看一些数据，在 COLUMNS 部分多加一些内容，如：</p>
<p><code>scan &#39;songdata&#39;, {COLUMNS =&gt; [&#39;data:artist_name&#39;, &#39;data:title&#39;], FILTER =&gt; &quot;SingleColumnValueFilter(&#39;data&#39;, &#39;artist_name&#39;, = , &#39;regexstring:^The Beatles.*&#39;)&quot;}</code></p>
<p>同样，我们也可以添加更多的 FILTER，用逻辑运算符 AND, OR, WHILE 等来进行组合。比如说，如果我们想在原来条件的基础上增加另一个条件：其 title 以 W 或者以 W 之后的字母开头，那么命令就可以这么写：</p>
<p><code>scan &#39;songdata&#39;, {COLUMNS =&gt; [&#39;data:artist_name&#39;, &#39;data:title&#39;], FILTER =&gt; &quot;SingleColumnValueFilter(&#39;data&#39;, &#39;artist_name&#39;, = , &#39;regexstring:^The Beatles.*&#39;) AND SingleColumnValueFilter(&#39;data&#39;, &#39;title&#39;, &gt;= , &#39;binaryprefix:W&#39;)&quot;}</code></p>
<p>另外提一点，在 FILTER 中使用了某一列，就需要在 COLUMNS 列表中也加入对应的列名，不然就会被忽略的，更多信息可以参阅<a href="http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/admin_hbase_filtering.html" target="_blank" rel="external">这篇日志</a>.</p>
<h3 id="HBase-Java-API"><a href="#HBase-Java-API" class="headerlink" title="HBase Java API"></a>HBase Java API</h3><p>HBase 也有其 Java API，可以用来创建、查看、修改和删除表，同样也可以插入和查询。</p>
<p><strong>建立连接</strong></p>
<p>首先我们需要建立连接，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">Configuration conf = HBaseConfiguration.create();</div><div class="line">conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, zookeeperAddress);</div><div class="line">conf.set(<span class="string">"hbase.zookeeper.property.clientport"</span>, <span class="string">"2181"</span>);</div><div class="line">HConnection conn = HConnectionManager.createConnection(conf);</div><div class="line">HTableInterface table = conn.getTable(tableName);</div></pre></td></tr></table></figure>
<p>前三行配置地址和端口，这里需要填写 master node 的 IP 地址。然后就可以创建 <code>HConnection</code> 并得到一个 <code>HTableInterface</code> 对象（用来处理特定 HBase 表）。</p>
<p>另一个创建 HBase table handler 的方法是</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">HTable table = <span class="keyword">new</span> HTable(conf, tableName);</div></pre></td></tr></table></figure>
<p>不过在新版本中已经被弃用了（所以直接不写出来不就好了嘛）</p>
<p>最常见的操作是 Get 和 Scan，get 用来获取某一行，scan 用来对多行操作，一般来说 scan 比 get 慢。不过我们这里会使用 scan。</p>
<p>下面是一个简单的例子，我们打印出所有 <code>artist_name</code> 以 “The Beatles” 开头的记录。更多详细的使用方法请参考 <a href="https://hbase.apache.org/0.94/apidocs/" target="_blank" rel="external">HBase Java API 文档</a>.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line"><span class="comment">// Create a new Scan object. By calling the default constructor, the entire table will be scanned.</span></div><div class="line">Scan scan = <span class="keyword">new</span> Scan();</div><div class="line"></div><div class="line"><span class="comment">// Binary representation of the column family name</span></div><div class="line"><span class="keyword">byte</span>[] bColFamily = Bytes.toBytes(<span class="string">"data"</span>)</div><div class="line"></div><div class="line"><span class="comment">// Binary representation of the column name.</span></div><div class="line"><span class="keyword">byte</span>[] bCol = Bytes.toBytes(<span class="string">"artist_name"</span>);</div><div class="line"></div><div class="line"><span class="comment">// This is used for regular expression matching. You should use different comparators based on specific requirements.</span></div><div class="line">RegexStringComparator comp = <span class="keyword">new</span> RegexStringComparator(<span class="string">"^The Beatles.*"</span>);</div><div class="line"></div><div class="line"><span class="comment">// This defines the filtering rules of our Scan object.</span></div><div class="line">Filter filter = <span class="keyword">new</span> SingleColumnValueFilter(bColFamily, bCol, CompareFilter.CompareOp.EQUAL, comp);</div><div class="line"></div><div class="line"><span class="comment">// Associate the filtering rules to our Scan object.</span></div><div class="line">scan.setFilter(filter);</div><div class="line"></div><div class="line"><span class="comment">// Use this if your query will return multiple rows.</span></div><div class="line">scan.setBatch(<span class="number">10</span>);</div><div class="line"></div><div class="line"><span class="comment">// Get the scan result.</span></div><div class="line">ResultScanner rs = songsTable.getScanner(scan);</div><div class="line"></div><div class="line"><span class="comment">// Each call of rs.next() will return one row.</span></div><div class="line"><span class="keyword">for</span> (Result r = rs.next(); r != <span class="keyword">null</span>; r = rs.next()) &#123;</div><div class="line">    <span class="comment">// r represents one row in the table. r.getValue returns the specific cell (determined by column family</span></div><div class="line">    <span class="comment">// and column name.</span></div><div class="line">    System.out.println(Bytes.toString(r.getValue(bColFamily, bCol)));</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// Cleanup</span></div><div class="line">rs.close();</div></pre></td></tr></table></figure>
<p>看看 <a href="http://hbase.apache.org/0.94/book/client.filter.html" target="_blank" rel="external">HBase tutorial on Client Request Filters</a> 对完成这部分的任务也很有帮助。</p>
<h3 id="解题攻略-3"><a href="#解题攻略-3" class="headerlink" title="解题攻略"></a>解题攻略</h3><p>这部分的任务就是完成 <code>runner.sh</code> 中的 17-21 题，需要改动的文件是 <code>HBaseTasks.java</code>。可以用下面的代码来运行 demo</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">javac HBaseTasks.java</div><div class="line">java HBaseTasks demo</div></pre></td></tr></table></figure>
<p>会打印出所有 <code>artist_name</code> 以 “The Beatles” 开头的记录（大小写敏感）</p>
<p>先把需要的文件 scp 到本地 <code>scp -i demo.pem ubuntu@ec2-54-209-165-121.compute-1.amazonaws.com:~/Project3_1/HBaseTasks.java ./</code></p>
<p>问题列表(17 题开始)：</p>
<ol>
<li>(17)找到以 “Total” 开头 “Water 结尾的歌名</li>
<li>(18)找到 “Kanye West” 的歌曲的歌名，名称以 “Apologies” 或 “Confessions” 开头，大小写敏感</li>
<li>(19)找到歌手名以 “Bob Marley” 为前缀的一首歌的歌名，长度大于 400，年份是 2000 年之后（包括 2000 年）</li>
<li>(20)找到歌手名包含 “Consequence” 的一首歌的歌名，歌名包含 “Family” 并且 <code>artist_hotttnesss</code> 要大于 1</li>
<li>(21)找到歌手名以 “Gwen Guthrie” 为前缀的一首歌的歌名，歌名包含 “Love” 但不包含 “Bitter” 或者 “Never”，年份为 1990</li>
</ol>
<p>然后按照前面的指引开一个 EMR，注意一定要开启 SSH，不然开了等于白开，开启之后连接上去 <code>ssh -i demo.pem hadoop@ec2-52-90-21-43.compute-1.amazonaws.com</code></p>
<p>然后用 <code>hadoop dfsadmin -report</code> 检查状态，不过说已经弃用这种命令写法了，如下：</p>
<p><img src="/images/14562658234752.jpg" alt=""></p>
<p>然后我们创建一个文件夹并下载对应的 csv 文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">mkdir P3_1</div><div class="line"><span class="built_in">cd</span> P3_1</div><div class="line">wget https://s3.amazonaws.com/15319-p31/million_songs_metadata.csv</div></pre></td></tr></table></figure>
<p>然后创建对应的 HDFS 目录，再把 csv 文件移过去：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">hadoop fs -mkdir /dawang</div><div class="line">hadoop fs -mkdir /dawang/csv</div><div class="line">hadoop fs -put ./million_songs_metadata.csv /dawang/csv/</div><div class="line"><span class="comment"># 查看</span></div><div class="line">hadoop fs -ls /dawang/csv/</div></pre></td></tr></table></figure>
<p><img src="/images/14562663033381.jpg" alt="hadoop fs -ls 结果"></p>
<p>然后进入 HBase Shell 操作 <code>hbase shell</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">hbase(main):001:0&gt; create &apos;songdata&apos;,&apos;data&apos;</div><div class="line">hbase(main):002:0&gt; list</div><div class="line">hbase(main):003:0&gt; describe &apos;songdata&apos;</div><div class="line">hbase(main):004:0&gt; exit</div></pre></td></tr></table></figure>
<p>结果如下所示：</p>
<p><img src="/images/14562664950809.jpg" alt=""></p>
<p>然后就需要具体的导入了，命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=<span class="string">","</span> -Dimporttsv.bulk.output=/hfile_p31 -Dimporttsv.columns=HBASE_ROW_KEY,data:title,data:song_id,data:release,data:artist_id,data:artist_mbid,data:artist_name,data:duration,data:artist_familiarity,data:artist_hotttnesss,data:year songdata /dawang/csv/million_songs_metadata.csv</div><div class="line"></div><div class="line">hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /hfile_p31 songdata</div></pre></td></tr></table></figure>
<p>完成之后测试一下 <code>hbase shell</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">hbase(main):001:0&gt; scan &apos;songdata&apos;</div></pre></td></tr></table></figure>
<p><img src="/images/14562672790636.jpg" alt="结果输出"></p>
<p>有很多需要注意的地方，尤其是比较字符串的时候，有些坑是一定要踩的（爆炸感谢 @jiexing）。</p>
<p>测试的话用 <code>./runner.sh hbase</code>，确定无误后使用 <code>./submitter -a dawang</code> 来进行提交，代码运行完成后输入提交密码即可。</p>
<p>一些需要注意的地方：</p>
<ol>
<li>Java 代码中需要填写 HBase 的 master node 的 dns</li>
<li>每题的答案在一行里输出</li>
<li>设置正确的日志级别来防止不必要的输出</li>
</ol>
<blockquote>
<p>SCAN 操作是 O(N) 的，GET 操作是 O(logN)，比较好的方式是，通过精心设计的数据库，用两次 GET 操作拿到起始和结束的 rowkey，这样就有极大的效率提高，详情参考<a href="https://blog.cloudera.com/blog/2013/04/how-scaling-really-works-in-apache-hbase/" target="_blank" rel="external">这里</a></p>
</blockquote>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="http://www.runoob.com/linux/linux-comm-join.html" target="_blank" rel="external">Linux join命令</a></li>
</ol>

    
  </div>


          </div>
          

  <p>热评文章</p>
  <div class="ds-top-threads" data-range="weekly" data-num-items="4"></div>


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="vault/cc-14.html"
           data-title="云计算 第 14 课 文件 vs 数据库" data-url="http://wdxtub.com/vault/cc-14.html">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/misc/avatar.jpg"
               alt="wdxtub" />
          <p class="site-author-name" itemprop="name">wdxtub</p>
          <p class="site-description motion-element" itemprop="description">人文/科学/读书/写作/思考/编程/架构/数据/广交朋友/@SYSU/@CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">710</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">874</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/wdxtub" target="_blank" title="GitHub">
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/wdxtub" target="_blank" title="微博">
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://douban.com/people/wdx" target="_blank" title="豆瓣">
                  
                  豆瓣
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/wdxtub" target="_blank" title="知乎">
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              不妨看看
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://zhchbin.github.io/" title="zhchbin" target="_blank">zhchbin</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.algorithmdog.com/" title="算法狗" target="_blank">算法狗</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.52cs.org/" title="我爱计算机" target="_blank">我爱计算机</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://jackqdyulei.github.io/" title="雷雷" target="_blank">雷雷</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://guojiex.github.io/" title="瓜瓜" target="_blank">瓜瓜</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.lofter.com/" title="我的 Lofter" target="_blank">我的 Lofter</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.com/interview/" title="刷题笔记" target="_blank">刷题笔记</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wdxtub</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"wdxblog"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementById('footer')
      || document.getElementById('footer')).appendChild(ds);
    })();
  </script>

  
    
      
      <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
      <script src="/js/src/hook-duoshuo.js"></script>
    
  





  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src=""></script>


  

  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
