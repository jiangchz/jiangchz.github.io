<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.lug.ustc.edu.cn/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content=",,,," />





  <link rel="alternate" href="/atom.xml" title="小土刀" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="MapReduce 虽好，但是对于需要迭代的计算，步骤繁琐且效率不高，于是振臂一呼，有了 Spark。这节课我们来通过具体的任务学习 Spark 相关知识和编程技巧。">
<meta name="keywords">
<meta property="og:type" content="website">
<meta property="og:title" content="云计算 第 20 课 Spark / GraphLab 动手玩">
<meta property="og:url" content="http://wdxtub.com/vault/cc-20.html">
<meta property="og:site_name" content="小土刀">
<meta property="og:description" content="MapReduce 虽好，但是对于需要迭代的计算，步骤繁琐且效率不高，于是振臂一呼，有了 Spark。这节课我们来通过具体的任务学习 Spark 相关知识和编程技巧。">
<meta property="og:image" content="http://wdxtub.com/images/14603811717061.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14603818043504.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14603831473158.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14604015470454.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14604017770026.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14604025416778.jpg">
<meta property="og:image" content="http://wdxtub.com/images/14603880787573.jpg">
<meta property="og:updated_time" content="2016-04-18T21:34:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="云计算 第 20 课 Spark / GraphLab 动手玩">
<meta name="twitter:description" content="MapReduce 虽好，但是对于需要迭代的计算，步骤繁琐且效率不高，于是振臂一呼，有了 Spark。这节课我们来通过具体的任务学习 Spark 相关知识和编程技巧。">
<meta name="twitter:image" content="http://wdxtub.com/images/14603811717061.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 4016951,
      author: '博主'
    }
  };
</script>

  <title>
  

  
    云计算 第 20 课 Spark / GraphLab 动手玩 | 小土刀
  
</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=59042340";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <div style="display: none;">
    <script src="http://s6.cnzz.com/stat.php?id=1260625611&web_id=1260625611" type="text/javascript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-left  ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小土刀</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Agony is my triumph</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-work">
          <a href="/2016/09/11/work-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-pencil"></i> <br />
            
            作品
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech">
          <a href="/2009/09/11/tech-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-battery-full"></i> <br />
            
            技术
          </a>
        </li>
      
        
        <li class="menu-item menu-item-life">
          <a href="/1990/09/11/life-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-bolt"></i> <br />
            
            生活
          </a>
        </li>
      
        
        <li class="menu-item menu-item-booklist">
          <a href="/1997/09/11/booklist-page" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-diamond"></i> <br />
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-thanks">
          <a href="/thanks" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-gift"></i> <br />
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="#" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
      <p>MapReduce 虽好，但是对于需要迭代的计算，步骤繁琐且效率不高，于是振臂一呼，有了 Spark。这节课我们来通过具体的任务学习 Spark 相关知识和编程技巧。</p>
<a id="more"></a>
<hr>
<h2 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h2><ol>
<li>使用 Spark 框架在大数据集上进行分布式迭代应用开发</li>
<li>利用 PageRank 分析 Twitter 社交图谱来找到最有影响力的用户</li>
</ol>
<p>我们前面使用 MapReduce 的时候，虽然数据是并行处理的，但是一般只需要一个 Map 和 Reduce 过程。随着 MapReduce 越来越广泛的使用，在面对诸如机器学习这种比较复杂的工作（许多多次迭代）时就有些力不从心了。在迭代计算中，前一次迭代的结果是这一次迭代的输入，但是使用 MapReduce 时，这些中间结果需要被写入到 HDFS 中，然后再由下一次迭代从 HDFS 中读取，需要在 IO 上浪费太多时间。那么能不能把数据保存在内存中，并且仍以某种机制保证容错性，以便能大幅提高效率呢？</p>
<p>答案当然是肯定的，于是我们有了 Spark。</p>
<h2 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h2><p>更多的介绍我会专门写日志介绍，这里主要是课程提供的一些信息。</p>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Spark 是由 UC Berkeley AMPLab 开发的开源集群计算框架，在特定的应用中，基于内存计算使其性能可以比 MapReduce 快 100 倍。下面的视频是 Spark 简介</p>
<p><a href="https://www.youtube.com/watch?v=mjgUJ9BLXco" target="_blank" rel="external">Video 1: Apache Spark Basics</a></p>
<p>在 Spark 框架中，最重要的是一类新的数据抽象，叫做 Resilient Distributed Dataset - RDD。RDD 是分布式存储在集群中的内存对象，按照值的范围或者哈希结果进行划分。与此同时 RDD 会记录关于数据进行的各种操作（每次操作都会生成新的 RDD），这样即使节点挂掉，也能够根据之前的操作日志重新得到损失的 RDD</p>
<p>我们可以用多种方式来操作 Spark：</p>
<ul>
<li>Shells - Python, Scala</li>
<li>APIs - Java, Scala, Python, R</li>
</ul>
<p>这里通过计算 abcd 出现的次数的例子来说明 RDD 可用操作</p>
<ul>
<li>载入 <code>&gt;&gt;&gt;input_RDD = sc.textFile(&quot;text.file&quot;)</code></li>
<li>Transformation，应用某种操作来生成新的 RDD <code>&gt;&gt;&gt;transform_RDD = input_RDD.filter(lambda x: &quot;abcd&quot; in x)</code></li>
<li>动作，计算并返回结果 <code>&gt;&gt;&gt;print &quot;Number of abcd:&quot; + transform_RDD.count()</code></li>
</ul>
<p>了解了基本概念，我们来看看 Spark 是如何工作的。假设我们需要在图上应用机器学习算法，Spark 会先把图保存为 RDD，具体要执行的算法会存储在 Spark Client 中，并根据算法映射到不同的 Spark 操作，最终 Cluster Manager 会把这些 Spark 操作具体调度到其他的 Worker 上进行执行。Spark 支持按照不同的因素进行调度，如优先级、实践、所需资源等等。具体如下所示：</p>
<p><img src="/images/14603811717061.jpg" alt="Figure 1: Spark Components."></p>
<p>使用 Spark 的时候，我们需要自己写驱动程序(driver program)来连接 Spark 集群，驱动程序定义了一个或多个 RDD，并在其中执行不同的动作。驱动程序也会通过有向无环图(DAG)来记录所有的操作。<code>Worker</code> 是一直都在运行的进程，这样我们才能把 RDD 保存在内存中。</p>
<p><img src="/images/14603818043504.jpg" alt="Figure 2: Spark Tasks"></p>
<p><code>SparkContext</code> 对象可以连接到不同类型的集群管理器来进行调度。集群管理区会隔离不同的 Spark 应用，目前 Spark 支持用 Scala, Java 和 Python 编写的程序。<code>SparkContext</code> 连接到集群管理器之后，就会让 Worker 节点进行计算。注意不同的应用有其 Executor。</p>
<p>这种机制的好处是隔离，坏处也就是数据共享不便。每个 Spark 应用都有自己的一组进程，运行 <code>main()</code> 函数的进程将是 driver，负责创建 <code>SparkContext</code> 对象，之后按照上图所示流程进行操作。</p>
<p>最后了解一下 Spark 生态系统</p>
<ul>
<li>Spark SQL: 类似 Hive，支持在不同 RDD 上进行类似 SQL 的操作</li>
<li>Spark Streaming: 对于流数据进行处理</li>
<li>MLlib: 机器学习库</li>
<li>GraphX: 图并行框架</li>
</ul>
<h3 id="编程初步"><a href="#编程初步" class="headerlink" title="编程初步"></a>编程初步</h3><p>还是通过经典的统计单词出现次数的例子来进行讲解，这里提供三种语言版本。</p>
<p>Scala，这里注意下划线是<a href="http://en.wikipedia.org/wiki/Syntactic_sugar" target="_blank" rel="external">语法糖</a>，其中 <code>reduceByKey(_ + _)</code> 等于 <code>reduceByKey(case (a, b) =&gt; a + b)</code>，这里的 case 是 Scala 特有的<a href="http://docs.scala-lang.org/tutorials/tour/case-classes.html" target="_blank" rel="external">概念</a>，更多的 Scala Spark 代码可以参见<a href="https://spark.apache.org/examples.html" target="_blank" rel="external">这里</a></p>
<figure class="highlight scala"><table><tr><td class="code"><pre><div class="line"><span class="keyword">val</span> file = spark.textFile(<span class="string">"hdfs:///input"</span>)</div><div class="line"><span class="keyword">val</span> counts = file.flatMap(line =&gt; line.split(<span class="string">" "</span>)</div><div class="line">                 .map(word =&gt; (word, <span class="number">1</span>))</div><div class="line">                 .reduceByKey(_ + _)</div><div class="line">counts.saveAsTextFile(<span class="string">"hdfs:///output"</span>)</div></pre></td></tr></table></figure>
<p>Java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><div class="line">JavaRDD file = spark.textFile(<span class="string">"hdfs:///input"</span>);</div><div class="line"></div><div class="line">JavaRDD words = file.flatMap(<span class="keyword">new</span> FlatMapFunction() &#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> Iterable <span class="title">call</span><span class="params">(String s)</span> </span>&#123; <span class="keyword">return</span> Arrays.asList(s.split(<span class="string">" "</span>)); &#125;</div><div class="line">&#125;);</div><div class="line"></div><div class="line">JavaPairRDD pairs = words.mapToPair(<span class="keyword">new</span> PairFunction() &#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> Tuple2 <span class="title">call</span><span class="params">(String s)</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> Tuple2(s, <span class="number">1</span>); &#125;</div><div class="line">&#125;);</div><div class="line"></div><div class="line">JavaPairRDD counts = pairs.reduceByKey(<span class="keyword">new</span> Function2() &#123;</div><div class="line">  <span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">(Integer a, Integer b)</span> </span>&#123; <span class="keyword">return</span> a + b; &#125;</div><div class="line">&#125;);</div><div class="line"></div><div class="line">counts.saveAsTextFile(<span class="string">"hdfs:///output"</span>);</div></pre></td></tr></table></figure>
<p>Python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><div class="line">file = spark.textFile(<span class="string">"hdfs:///input"</span>)</div><div class="line">counts = file.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>)) \</div><div class="line">             .map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>)) \</div><div class="line">             .reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</div><div class="line">counts.saveAsTextFile(<span class="string">"hdfs:///output"</span>)</div></pre></td></tr></table></figure>
<p>下图描述了这个过程，具体不再讲解</p>
<p><img src="/images/14603831473158.jpg" alt="Figure 3: Wordcount Example in Spark"></p>
<p>这里多讲一些 Scala 中的 <code>Map</code> 和 <code>Reduce</code> 函数，主要是 <code>map(func)</code> 和 <code>flatMap(func)</code>，以及 <code>reduce(func)</code> 和 <code>reduceByKey(func)</code> 的区别，请仔细阅读下列代码</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><div class="line">rdd = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>),</div><div class="line">rdd.map(x =&gt; (x, x + <span class="number">1</span>)) =&gt; ((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">3</span>), (<span class="number">3</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">5</span>))</div><div class="line">rdd.flatMap(x =&gt; (x, x + <span class="number">1</span>)) =&gt; (<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>)</div><div class="line"></div><div class="line">rdd = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</div><div class="line">rdd.reduce(<span class="keyword">case</span> (a, b) =&gt; a + b) =&gt; <span class="number">10</span></div><div class="line"></div><div class="line">rdd = ((<span class="number">1</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">3</span>), (<span class="number">2</span>, <span class="number">4</span>), (<span class="number">2</span>, <span class="number">5</span>))</div><div class="line">rdd.reduceByKey(<span class="keyword">case</span> (a, b) =&gt; a + b) =&gt; ((<span class="number">1</span>, <span class="number">5</span>), (<span class="number">2</span>, <span class="number">9</span>))</div></pre></td></tr></table></figure>
<h3 id="启动-Spark-集群"><a href="#启动-Spark-集群" class="headerlink" title="启动 Spark 集群"></a>启动 Spark 集群</h3><p>有两种方式启动 Spark 集群，简单的是使用 AWS EMR，详细的指引在<a href="https://docs.aws.amazon.com/ElasticMapReduce/latest/ReleaseGuide/emr-spark-launch.html" target="_blank" rel="external">这里</a>，大致的步骤为：</p>
<ol>
<li>创建集群 - 高级选项</li>
<li>在设置中选择 Amazon EMR-4.2.0，勾上 Spark</li>
<li>软件设置中填写 <code>[{&quot;classification&quot;:&quot;spark&quot;,&quot;properties&quot;:{&quot;maximizeResourceAllocation&quot;:&quot;true&quot;}}]</code>（不配置的话将无法最大程度利用硬件）</li>
<li>名字、实例类型及数量、标签、EC2 密钥一并设置</li>
<li>开启成功之后，可以 ssh 到 master 并使用 <code>spark-submit</code> 来提交任务，或者也可以在代码中添加步骤</li>
</ol>
<p>另一种方式是使用 ec2 脚本，具体的步骤在<a href="https://spark.apache.org/docs/latest/ec2-scripts.html" target="_blank" rel="external">这里</a>，还有一个简单的<a href="https://www.youtube.com/watch?v=3pXjl3NTuvk" target="_blank" rel="external">介绍视频</a>，这里不再赘述。</p>
<h2 id="GraphLab"><a href="#GraphLab" class="headerlink" title="GraphLab"></a>GraphLab</h2><p>CMU 开发的分布式 graph parallel 框架，用来在大数据上执行机器学习和数据挖掘算法。GraphLab 把具体的计算抽象成为节点(vertex)，而计算之间的数据关系抽象成为边(edge)。</p>
<p>GraphLab 使用以节点为中心的模型，用户的程序会被表示为一个更新函数，作用于一个中心节点及其相邻的边和节点（是不是和 PageRank 的计算过程很配？）具体的计算可以同步通过 Bulk Synchronous Model(BSP) 来完成，也可以通过弹性一致性模型异步完成。</p>
<p>在 GraphLab 1.0 中，数据以边来切分(edge-cut)，也就是说一条边连接的两个端点可能在不同的机器上。如下图所示：</p>
<p><img src="/images/14604015470454.jpg" alt="Figure 5: Edge-cut in GraphLab 1.0"></p>
<p>但是在 GraphLab 2.0(PowerGraph) 中，考虑到类似社交网络这样的图会有超级热点(power-law property)，如果仍旧用边切分，可能会出现超级节点和其他节点大多数时候处于不同的机器上，这样就会导致性能损失。所以 GraphLab 2.0 选择使用节点来划分(vertex-cut)。这样的好处是，一条边连接的两个节点肯定在一台机器上，对于每个节点来说，可能会有几个不同的复制，其中一个将成为 master，其他的则是 mirror，如下图所示：</p>
<p><img src="/images/14604017770026.jpg" alt="Figure 6: Vertex-cut in GraphLab 2.0"></p>
<p>具体的编程和我们之前的方式也有些不同，我们编写的程序会在每个节点上运行，具体有 3 个步骤：</p>
<ol>
<li>Gather: 对于每个节点来说，其 master 和 mirror 节点会从相邻的边和节点收集所需信息</li>
<li>Apply: 所有收集到的信息会在 master 节点完成计算并更新节点，完成之后这个改动会同步到其他的 mirror 节点中</li>
<li>Scatter: master 和 mirror 节点选择更新对应相邻的边和节点，收到消息的节点会被激活，继续执行对应的计算</li>
</ol>
<p><img src="/images/14604025416778.jpg" alt="Figure 7: Gather, Apply, Scatter in a user-defined program"></p>
<p>之后提到的 GraphLab，统一指 GraphLab 2.0.</p>
<h3 id="启动-GraphLab-集群"><a href="#启动-GraphLab-集群" class="headerlink" title="启动 GraphLab 集群"></a>启动 GraphLab 集群</h3><p>这里我们就不能使用 EMR 了，需要手动配置，具体步骤如下：</p>
<ol>
<li>在<a href="https://github.com/dato-code/PowerGraph" target="_blank" rel="external">这里</a>下载 GraphLab</li>
<li>解压并进入 <code>PowerGraph-master/scripts/ec2</code><ul>
<li>进入 <code>graphlab-master</code> 文件夹，执行 <code>doxygen</code> 可以生成文档，具体在 <code>graphlab-master/doc/doxygen/html</code> 中，点击 <code>index.html</code> 就可以在浏览器中查看文档了</li>
</ul>
</li>
<li>在环境变量中配置 AWS 密钥<ul>
<li><code>export AWS_ACCESS_KEY_ID=[your AWS access key]</code></li>
<li><code>export AWS_SECRET_ACCESS_KEY=[your AWS secret key]</code></li>
</ul>
</li>
<li>启动 GraphLab 集群 <code>./gl-ec2 -k [keypair] -i [key-file] -t [instance-type] -s [num-slaves] -r us-east-1 -a ami-89adafe3 launch [cluster-name]</code></li>
<li>给刚启动的实例打上标签 <code>Project:4.2</code></li>
<li>使用该命令登录 <code>./gl-ec2 -k [keypair] -i [key-file] -r us-east-1 login [cluster-name]</code></li>
<li>使用该命令关闭集群 <code>./gl-ec2 -k [keypair] -i [key-file] -r us-east-1 destroy [cluster-name]</code></li>
</ol>
<h2 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a>任务目标</h2><ul>
<li>打标签 <code>Project:4.2</code></li>
<li>提交 <code>AMI for bonus 2(GraphLab): ami-e1f5fa8b</code>, <code>m1.small</code></li>
<li>使用 AWS EMR 的 Spark，注意不能使用 GraphX 和 MLlib 中的函数（就是要自己写）</li>
</ul>
<h3 id="任务-1-遍历-Twitter-社交图谱"><a href="#任务-1-遍历-Twitter-社交图谱" class="headerlink" title="任务 1 遍历 Twitter 社交图谱"></a>任务 1 遍历 Twitter 社交图谱</h3><blockquote>
<p>有大 V 的地方，就有江湖。想要混入江湖，就要跟好大 V。</p>
</blockquote>
<p>这里使用的数据集来自 <a href="http://law.di.unimi.it/webdata/twitter-2010/" target="_blank" rel="external">Kwak</a>，共 8.66 GB。在 <code>s3://cmucc-datasets/TwitterGraph.txt</code> 可以下载到。</p>
<p>具体数据存着的边列表，格式是 <code>(u,v)</code> 表示 <code>u</code> 关注了 <code>v</code>。</p>
<p>我需要做的是找到『边』和『节点』的数量，注意 <code>(u,v)</code> 和 <code>(v,u)</code> 是两条边。</p>
<blockquote>
<p>提交方式</p>
</blockquote>
<ol>
<li>登录到 master 机器，下载 <code>https://s3.amazonaws.com/15-319-s16/task1_submitter.tgz</code></li>
<li>解压并进入文件夹</li>
<li>在 <code>answer</code> 文件中填写答案，并把代码复制到 <code>task1</code> 文件夹中</li>
<li>运行 <code>./submitter</code> 进行提交</li>
</ol>
<blockquote>
<p>工作日志</p>
</blockquote>
<ul>
<li>开启 EMR Spark 之后，登录 <code>ssh -i ../demo.pem hadoop@ec2-52-207-252-75.compute-1.amazonaws.com</code></li>
<li>安装 tmux <code>sudo yum install tmux</code></li>
<li>复制数据 <code>hadoop distcp s3://cmucc-datasets/TwitterGraph.txt /</code></li>
<li>制作一个测试数据并放到 hdfs 中 <code>hadoop fs -put ./test.txt /</code></li>
<li>查看文件 <code>hadoop fs -ls /</code></li>
<li>进入 spark-shell</li>
</ul>
<p>Spark Shell 部分</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs:///test.txt"</span>).cache</div><div class="line"><span class="comment">// 因为 Lazy Evaluation，所以直到执行这一句才载入，测试数据也正好是我们需要的 1000 行</span></div><div class="line">scala&gt; textFile.count()</div><div class="line">res1: <span class="type">Long</span> = <span class="number">1000</span></div><div class="line"></div><div class="line"><span class="comment">// 统计用户和边数量</span></div><div class="line">scala&gt; <span class="keyword">val</span> userCount = textFile.flatMap(line =&gt; line.split(<span class="string">"\t"</span>)).cache</div><div class="line">scala&gt; <span class="keyword">val</span> q1Count = userCount.map(id =&gt; (id, <span class="number">1</span>)).reduceByKey(_ + _).cache</div><div class="line">scala&gt; q1Count.count()</div><div class="line"></div><div class="line">scala&gt; <span class="keyword">val</span> edgeCount = textFile.map(id =&gt; (id, <span class="number">1</span>)).reduceByKey(_ + _).cache</div><div class="line">scala&gt; edgeCount.count()</div><div class="line"></div><div class="line"><span class="comment">// ----------------</span></div><div class="line"><span class="comment">// 重启 spark-shell</span></div><div class="line">scala&gt; <span class="keyword">val</span> textFile = sc.textFile(<span class="string">"hdfs:///TwitterGraph.txt"</span>).cache</div><div class="line"><span class="comment">// 统计行数，顺带载入 cache</span></div><div class="line">scala&gt; textFile.count()</div><div class="line">res0: <span class="type">Long</span> = <span class="number">517970607</span></div><div class="line"></div><div class="line"><span class="comment">// 继续执行各项统计，会分成不同的任务执行</span></div><div class="line">scala&gt; <span class="keyword">val</span> userCount = textFile.flatMap(line =&gt; line.split(<span class="string">"\t"</span>)).map(id =&gt; (id, <span class="number">1</span>)).reduceByKey(_ + _).cache</div><div class="line">scala&gt; userCount.count()</div><div class="line">res1: <span class="type">Long</span> = <span class="number">2315848</span></div><div class="line"></div><div class="line">scala&gt; <span class="keyword">val</span> edgeCount = textFile.map(id =&gt; (id, <span class="number">1</span>)).reduceByKey(_ + _).cache</div><div class="line">scala&gt; edgeCount.count()</div><div class="line">res2: <span class="type">Long</span> = <span class="number">517970363</span></div></pre></td></tr></table></figure>
<p>得到数据后，提交测试一下</p>
<ul>
<li>下载提交器 <code>wget https://s3.amazonaws.com/15-319-s16/task1_submitter.tgz</code></li>
<li>解压 <code>tar xvf task1_submitter.tgz; cd task1</code></li>
</ul>
<h3 id="任务-2-计算每个用户的粉丝数量"><a href="#任务-2-计算每个用户的粉丝数量" class="headerlink" title="任务 2 计算每个用户的粉丝数量"></a>任务 2 计算每个用户的粉丝数量</h3><p>这个任务的执行，需要运行给定的 submitter 来进行提交。</p>
<p>具体的步骤为：</p>
<ol>
<li>下载 <code>https://s3.amazonaws.com/15-319-s16/task2-follower.tgz</code></li>
<li>写一个 spark 程序，生成如下的数据 <code>[user_id]\t[num_followers]</code><ul>
<li>Python 的话脚本名为 <code>follower.py</code></li>
<li>Java/Scala 的话打包为 <code>follower.jar</code> 且 main class 为 <code>Follower</code></li>
</ul>
</li>
<li>submitter 会在 home 目录运行 Spark 程序，可以在 <code>task2</code> 文件夹中用下面命令进行测试<ul>
<li>Python: <code>spark-submit follower.py</code></li>
<li>Java/Scala: <code>spark-submit --class Follower follower.jar</code></li>
</ul>
</li>
<li>submitter 会寻找在 <code>hdfs://follower-output</code> 中的输出，不需要自己进行 merge 和 sort</li>
<li>把所用的代码文件拷贝到 <code>task2</code> 文件夹中的 <code>src</code> 文件夹中，在 <code>references</code> 中记下有用的链接</li>
<li>最终提交命令 <code>chmod +x follower-submitter; ./follower-submitter</code></li>
</ol>
<blockquote>
<p>工作日志</p>
</blockquote>
<ul>
<li>下载提交器 <code>wget https://s3.amazonaws.com/15-319-s16/task2-follower.tgz</code></li>
<li>解压 <code>tar xvf task2-follower.tgz; cd task2</code></li>
<li>需要自己用 sbt 压缩成 scala 的 jar 包（Mac 上测试通过）<ul>
<li><code>brew install sbt</code></li>
<li><code>sbt clean; sbt package</code></li>
</ul>
</li>
<li>拷贝到 EMR 中 <code>cp ./q2/target/scala-2.10/follower_2.10-1.0.jar ./follower.jar; scp -i ./demo.pem ./follower.jar hadoop@ec2-54-86-168-196.compute-1.amazonaws.com:~/task2/</code></li>
<li>清理输出文件夹（如果之前测试了的话）<code>hadoop fs -rm -r /follower-output</code> </li>
<li>提交即可，我的用时是 171s</li>
</ul>
<h3 id="任务-3-根据影响力给用户排序"><a href="#任务-3-根据影响力给用户排序" class="headerlink" title="任务 3 根据影响力给用户排序"></a>任务 3 根据影响力给用户排序</h3><p>这里主要使用的是 <a href="https://en.wikipedia.org/wiki/PageRank" target="_blank" rel="external">PageRank</a> 算法，具体不赘述，参考下图的公式：</p>
<p><img src="/images/14603880787573.jpg" alt="Figure 4: PageRank Expression"></p>
<blockquote>
<p>PageRank 实现细节</p>
</blockquote>
<ul>
<li>Initial Rank values<ul>
<li>初始值每个用户都是 1，可以用一个 <code>map</code> 操作来完成</li>
</ul>
</li>
<li>Damping Factor<ul>
<li>也就是上面公式中的 d，这里我们用 <code>0.85</code></li>
</ul>
</li>
<li>Output Format<ul>
<li>输出格式要和输入格式一样，这样才能保证能够迭代进行计算</li>
</ul>
</li>
<li>Dangling Users<ul>
<li>指的是那些不关注任何人的用户，每次迭代需要重新分配其权重</li>
</ul>
</li>
</ul>
<p>举个例子，一开始的输入数据是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">key: user1 rank: 1.0 follows: user2 user3 </div><div class="line">key: user2 rank: 1.0 follows: user3 user1</div></pre></td></tr></table></figure>
<p>经过第一次迭代之后，会得到如下的分布，这里稍微解释一下，为什么 user1 得到的是 0.5 呢？因为我们可以看到只有 user2 关注 user1，而 user2 一共关注了 2 人，所以其权重被平均分成两份，于是就是 0.5；user2 得到 0.5 也是同理。而 user3 被 user1 和 user2 关注，各从他们身上拿到了 0.5，所以是 1.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">key: user1 contributions received: 0.5 follows: user2 user3 </div><div class="line">key: user2 contributions received: 0.5 follows: user3 user1 </div><div class="line">key: user3 contributions received: 1.0 follows:</div></pre></td></tr></table></figure>
<p>这里 user3 没有关注的人，就成了『异类』，所以必须把这类节点的权重平均分给所有的节点，这里 user3 的初始权重是 1，因为一共有 3 个用户，可得：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><div class="line">user1 = 0.15 + 0.85 * (0.5 + 1.0/3) = 0.8583</div><div class="line">user2 = 0.15 + 0.85 * (0.5 + 1.0/3) = 0.8583</div><div class="line">user3 = 0.15 + 0.85 * (1.0 + 1.0/3) = 1.2834</div></pre></td></tr></table></figure>
<p>之后就继续按照这样的模式计算下去，直到指定次数或者收敛（排名不再变动）</p>
<blockquote>
<p>执行与提交</p>
</blockquote>
<p>复制数据 <code>hadoop distcp s3://cmucc-datasets/TwitterGraph.txt /</code></p>
<ol>
<li>下载 <code>wget https://s3.amazonaws.com/15-319-s16/task3-pagerank.tgz</code><ul>
<li>解压 <code>tar xvf task3-pagerank.tgz; cd task3</code></li>
</ul>
</li>
<li>写一个 spark 程序，生成如下的数据 <code>[user_id]\t[PageRank_value]</code>，共进行 <code>10</code> 次迭代<ul>
<li>Python 的话脚本名为 <code>pagerank.py</code></li>
<li>Java/Scala 的话打包为 <code>pagerank.jar</code> 且 main class 为 <code>PageRank</code></li>
</ul>
</li>
<li>submitter 会在 home 目录运行 Spark 程序，可以在 <code>task3</code> 文件夹中用下面命令进行测试<ul>
<li>Python: <code>spark-submit pagerank.py</code></li>
<li>Java/Scala: <code>spark-submit --class PageRank pagerank.jar</code></li>
</ul>
</li>
<li>submitter 会寻找在 <code>hdfs:///pagerank-output</code> 中的输出，不需要自己进行 merge 和 sort</li>
<li>把所用的代码文件拷贝到 <code>task3</code> 文件夹中的 <code>src</code> 文件夹中，在 <code>references</code> 中记下有用的链接</li>
<li>最终提交命令 <code>chmod +x pagerank-submitter; ./pagerank-submitter</code></li>
</ol>
<p>使用的命令</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><div class="line">sbt clean; sbt package</div><div class="line"></div><div class="line">cp ./q3/target/scala-2.10/pagerank_2.10-1.0.jar ./pagerank.jar; scp -i ./demo.pem ./pagerank.jar hadoop@ec2-52-207-241-86.compute-1.amazonaws.com:~/task3/</div><div class="line"></div><div class="line"><span class="comment"># 清理输出文件夹（如果之前测试了的话）</span></div><div class="line">hadoop fs -rm -r /pagerank-output</div></pre></td></tr></table></figure>
<h3 id="Bonus-1-加速！Spark！"><a href="#Bonus-1-加速！Spark！" class="headerlink" title="Bonus 1 加速！Spark！"></a>Bonus 1 加速！Spark！</h3><p>任务很简单，就是让任务 3 能在 30 分钟内完成，具体的步骤也是一样的。下面是一些技巧：</p>
<ol>
<li>优化代码。深入理解 RDD manipulation。理解 Spark 中的 lazy transformation。仔细思考是否需要、何时需要使用 <code>cache()</code>, <code>collect()</code>, <code>persist()</code>, <code>unpersist()</code> 函数，可以在<a href="https://spark.apache.org/docs/1.2.1/programming-guide.html#rdd-persistence" target="_blank" rel="external">这里</a>进一步了解</li>
<li>监控实例的状态，看看有没有充分利用，如果是资源不够的话，考虑多申请一些。参考命令 <code>htop</code>, <code>iotop</code>, <code>iostat</code></li>
<li>了解 Spark 的参数，如 <code>spark.driver.memory</code>, <code>spark.executor.memory</code>, <code>spark.executor.cores</code>, <code>spark.python.worker.memory</code>，可以在<a href="http://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="external">这里</a>进一步了解</li>
<li>因为 RDD 是只读的，并且我们的 PageRank 需要迭代十次，所以会有许多中间结果 RDD 或者 grabage。垃圾回收可以极大提高性能，对应的参数是 <code>spark.memory.fraction</code>, <code>spark.memory.storageFraction</code>，可以在<a href="https://spark.apache.org/docs/1.2.0/tuning.html#garbage-collection-tuning" target="_blank" rel="external">这里</a>进一步了解</li>
</ol>
<h3 id="Bonus-2-在-GraphLab-上实现-PageRank"><a href="#Bonus-2-在-GraphLab-上实现-PageRank" class="headerlink" title="Bonus 2 在 GraphLab 上实现 PageRank"></a>Bonus 2 在 GraphLab 上实现 PageRank</h3><p>在前面的计算中，我们可以发现 PageRank 需要其邻居的相关信息，这就和 graph parallel 模型非常搭。这个任务中，我们会用 GraphLab 来实现 PageRank。具体的步骤为</p>
<ol>
<li>开启 GraphLab 集群并登录到 master 实例中</li>
<li>进入 <code>graphlab/apps/pagerank</code> 目录，可以看到 <code>pagerank.cpp</code> 文件，我们需要完成这份代码<ul>
<li>改好之后传过去 <code>scp -i demo.pem ./pagerank.cpp ubuntu@ec2-52-91-192-149.compute-1.amazonaws.com:~/graphlab/apps/pagerank/</code></li>
</ul>
</li>
<li>完成之后，进入 <code>graphlab/release/apps/pagerank</code> 文件夹，执行 <code>make</code> 来进行编译</li>
<li>编译之后，在当前目录下使用 <code>~/graphlab/scripts/mpirsync</code> 来把程序分发到所有的机器上</li>
<li>使用下面的命令来运行 PageRank 应用，进行 15 次迭代<ul>
<li><code>mpiexec -hostfile ~/machines -n [num_of_machines] ./my_pagerank --graph ~/data/ --iterations 15 --saveprefix [path_of_output]</code> </li>
</ul>
</li>
<li>收集所有的输出文件，并在 master 实例中 merge</li>
</ol>
<blockquote>
<p>提交方式</p>
</blockquote>
<ol>
<li>开启一个 <code>ami-e1f5fa8b</code> 的 <code>m1.small</code> 实例，并把输出文件拷贝过来</li>
<li>把数据载入到 MySQL 数据库中，可以用 <code>mysql -uuser -ppassword cc</code> 来登录数据库，表名为 <code>bonus</code></li>
<li>数据载入之后，使用 <code>sudo nohup python server.py 80 &amp;</code> 启动服务器</li>
<li>进入 <code>Project4_2/bonus</code> 目录，把 <code>pagerank.cpp</code> 文件复制过去并执行 <code>submitter_bonus</code> 来进行提交</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="http://zhangyi.farbox.com/post/kai-yuan-kuang-jia/pagerank-based-on-spark" target="_blank" rel="external">Spark中实现基础的PageRank</a></li>
<li><a href="https://endymecy.gitbooks.io/spark-programming-guide-zh-cn/content/" target="_blank" rel="external">Spark 编程指南简体中文版</a></li>
</ul>

    
  </div>


          </div>
          

  <p>热评文章</p>
  <div class="ds-top-threads" data-range="weekly" data-num-items="4"></div>


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="vault/cc-20.html"
           data-title="云计算 第 20 课 Spark / GraphLab 动手玩" data-url="http://wdxtub.com/vault/cc-20.html">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/misc/avatar.jpg"
               alt="wdxtub" />
          <p class="site-author-name" itemprop="name">wdxtub</p>
          <p class="site-description motion-element" itemprop="description">人文/科学/读书/写作/思考/编程/架构/数据/广交朋友/@SYSU/@CMU</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">710</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              
                <span class="site-state-item-count">874</span>
                <span class="site-state-item-name">标签</span>
              
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/wdxtub" target="_blank" title="GitHub">
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/wdxtub" target="_blank" title="微博">
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://douban.com/people/wdx" target="_blank" title="豆瓣">
                  
                  豆瓣
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/wdxtub" target="_blank" title="知乎">
                  
                  知乎
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              不妨看看
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://zhchbin.github.io/" title="zhchbin" target="_blank">zhchbin</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.algorithmdog.com/" title="算法狗" target="_blank">算法狗</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.52cs.org/" title="我爱计算机" target="_blank">我爱计算机</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://jackqdyulei.github.io/" title="雷雷" target="_blank">雷雷</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://guojiex.github.io/" title="瓜瓜" target="_blank">瓜瓜</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.lofter.com/" title="我的 Lofter" target="_blank">我的 Lofter</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wdxtub.com/interview/" title="刷题笔记" target="_blank">刷题笔记</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2013 - 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wdxtub</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"wdxblog"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementById('footer')
      || document.getElementById('footer')).appendChild(ds);
    })();
  </script>

  
    
      
      <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
      <script src="/js/src/hook-duoshuo.js"></script>
    
  





  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';                
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = true;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = data.url;
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '' && data_content != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title < 0 && index_content < 0 ){
                                isMatch = false;
                            } else {
                                if (index_content < 0) {
                                    index_content = 0;
                                }
                                if (i == 0) {
                                    first_occur = index_content;
                                }
                            }
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });
                            
                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').mousedown(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src=""></script>


  

  
<script type="text/javascript" async src="//push.zhanzhang.baidu.com/push.js">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
</html>
